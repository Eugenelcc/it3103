{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "human-activity-recognition.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nyp-sit/it3103/blob/main/week15/human_activity_recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYr0jAYAexJw"
      },
      "source": [
        "# Human Activity Recognition using 2D-Pose\n",
        "\n",
        "In this practical, we will be using data from the following Github repository to train our model to recognize human activities through \"motion capture\". \n",
        "\n",
        "https://github.com/stuarteiffert/RNN-for-Human-Activity-Recognition-using-2D-Pose-Input\n",
        "\n",
        "The dataset is also available for download from Polymall, and also from AWS. GO ahead to download the file from Polymall and take a look at its contents.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wbeL6tzpexJw"
      },
      "source": [
        "## Section 1 - Import Libraries and Setup Folders\n",
        "\n",
        "Run the following cell, as is, to import all necessary libraries and set up folders."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mtw7A3kzexJw"
      },
      "source": [
        "!wget https://nyp-aicourse.s3.ap-southeast-1.amazonaws.com/it3103/2D-Pose-Data.zip\n",
        "!unzip 2D-Pose-Data.zip\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXILUY9CZ0mq"
      },
      "source": [
        "Then, run the following cell to import the necesary libraries that we need to use.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-IziWQLgvOZ"
      },
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "import math\n",
        "from tqdm import tqdm\n",
        "from datetime import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "from matplotlib import rc\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation, Input, Bidirectional, Dropout, LSTM, TimeDistributed, Flatten\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITgEdYtcexJw"
      },
      "source": [
        "## Section 2 - Declare Functions for Processing and Normalizing Data\n",
        "\n",
        "### Remapping of Joint Coordinates \n",
        "\n",
        "The dataset that we are using to train our model uses the CMU OpenPose format to the human poses. \n",
        "\n",
        "The CMU OpenPose format stores the coordinates of the joints in the following order:\n",
        "0. Nose X, Y\n",
        "1. Neck X, Y\n",
        "2. Right Shoulder X, Y\n",
        "3. Right Elbow X, Y\n",
        "4. Right Wrist X, Y\n",
        "5. Left Shoulder X, Y\n",
        "6. Left Elbow X, Y\n",
        "7. Left Wrist X, Y\n",
        "8. Right Hip X, Y\n",
        "9. Right Knee X, Y\n",
        "10. Right Ankle X, Y\n",
        "11. Left Hip X, Y\n",
        "12. Left Knee X, Y\n",
        "13. Left Ankle X, Y\n",
        "14. Right Eye X, Y\n",
        "15. Left Eye X, Y\n",
        "16. Right Ear X, Y\n",
        "17. Left Ear X, Y\n",
        "\n",
        "\n",
        "Let's run the following cell with an empty placeholder function that does no processing to the skeleton keypoints.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gfwOv5fxexJw"
      },
      "source": [
        "\n",
        "# Process OpenPose's Joints\n",
        "#\n",
        "def process_joints(x):\n",
        "\n",
        "    # No processing yet.\n",
        "    return x\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJSNwLt1exJw"
      },
      "source": [
        "## Section 3 - Declare Functions to Perform Procesing\n",
        "\n",
        "Update the following codes:\n",
        "\n",
        "1. In the first part, call the process_joints on the row variable and append the results into the x list. That can be achieved by doing this:\n",
        "\n",
        "   ```\n",
        "      x.append(process_joints(row))\n",
        "   ```\n",
        "\n",
        "2. Convert the input from the row into a one-hot vector. This can be achieved using the following codes:\n",
        "\n",
        "   ```\n",
        "        one_hot = [0] * num_of_classes\n",
        "        one_hot[row[0] - 1] = 1\n",
        "        y.append(one_hot)\n",
        "   ```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Euwp_RcR4aD"
      },
      "source": [
        "df = pd.read_csv('2D-Pose-Data/X_train.txt', header=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZhxD-86oSAzL"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQNj4bCdDToz"
      },
      "source": [
        "label_df = pd.read_csv('2D-Pose-Data/Y_train.txt', header=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZJVDsIRDf4w"
      },
      "source": [
        "label_df[0].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVZiFZBXSdNQ"
      },
      "source": [
        "count = 0\n",
        "\n",
        "for row in df.itertuples(index=False):\n",
        "    print(row)\n",
        "    count += 1\n",
        "    if count == 4:\n",
        "        break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WvwPwt8exJw"
      },
      "source": [
        "### sequence length is 32 time steps, each timestep has 36 features (x,y) of 18 joints\n",
        "\n",
        "# This function processes the x input data.\n",
        "#\n",
        "def load_x(infilepath):\n",
        "    df = pd.read_csv(infilepath, header=None)\n",
        "    \n",
        "    print (\"Processing \" + infilepath)\n",
        "    x = []\n",
        "    for row in tqdm(df.itertuples(index=False)):\n",
        "\n",
        "        # TODO:\n",
        "        # Load each row from the CSV file and call the \n",
        "        # process_joints function.\n",
        "        #\n",
        "        x.append(process_joints(row))\n",
        "\n",
        "    x = np.array(x)\n",
        "    x = np.reshape(x, (int(x.shape[0] / 32), 32, 36))\n",
        "    \n",
        "    print (\"Done.\")\n",
        "    return x\n",
        "    \n",
        "\n",
        "# This function processes the y labels.\n",
        "#\n",
        "def load_y_into_one_hot(infilepath, num_of_classes):\n",
        "    df = pd.read_csv(infilepath, header=None)\n",
        "    \n",
        "    print (\"Processing \" + infilepath)\n",
        "    \n",
        "    y = []\n",
        "    index = 0\n",
        "    for row in tqdm(df.itertuples(index=False)):\n",
        "\n",
        "        # TODO: \n",
        "        # Convert each row in the y file into a one-hot \n",
        "        # vector.\n",
        "        #\n",
        "        one_hot = [0] * num_of_classes\n",
        "        one_hot[row[0] - 1] = 1\n",
        "        y.append(one_hot)\n",
        "\n",
        "        index+=1\n",
        "            \n",
        "    y = np.array(y)\n",
        "    \n",
        "    print (\"Done.\")  \n",
        "    return y\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3MRvHzEbexJw"
      },
      "source": [
        "## Section 4 - Load and Process the Data\n",
        "\n",
        "Modify the codes into the cell below to load the x and y data into the variables x_train, x_test, y_train, y_test accordingly.\n",
        "\n",
        "```\n",
        "# Load our X input data\n",
        "x_train = load_x(\"2D-Pose-Data/X_train.txt\")\n",
        "x_test = load_x(\"2D-Pose-Data/X_test.txt\")\n",
        "\n",
        "# Load our Y classification data\n",
        "y_train = load_y_into_one_hot(\"2D-Pose-Data/Y_train.txt\", 6)\n",
        "y_test = load_y_into_one_hot(\"2D-Pose-Data/Y_test.txt\", 6)\n",
        "```\n",
        "\n",
        "In the meantime, it will be a good idea to study CSV data to understand how the coordinates are saved from the training data. Observe how some X, Y coordinates are zero, and think about how this can affect processing or affect accuracy.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "POrMHlfRexJw",
        "scrolled": true
      },
      "source": [
        "# TODO:\n",
        "# Load our X input data\n",
        "#\n",
        "#...#\n",
        "X_train = load_x(\"2D-Pose-Data/X_train.txt\")\n",
        "X_test = load_x(\"2D-Pose-Data/X_test.txt\")\n",
        "\n",
        "# TODO:\n",
        "# Load our Y classification data\n",
        "#\n",
        "#...#\n",
        "y_train = load_y_into_one_hot(\"2D-Pose-Data/Y_train.txt\", 6)\n",
        "y_test = load_y_into_one_hot(\"2D-Pose-Data/Y_test.txt\", 6)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PN8DLNifV2ZR"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pRpqIItcr_iC"
      },
      "source": [
        "## Section 5 - Visualize Our Dataset\n",
        "\n",
        "Unlike images or structured data, these set of data can't be displayed as they are since they will not make any sense. \n",
        "\n",
        "Try running the first cell below to display the inputs like intensities of pixels in an image. \n",
        "\n",
        "The following is what you can use to display a 2D (32 x 36 \"pixels\") image of the first sample.\n",
        "\n",
        "```\n",
        "sample = 0\n",
        "plt.imshow(X_train[sample])\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AhGej51-wdJI"
      },
      "source": [
        "# TODO:\n",
        "# Each sample is a two-dimension array of (32 frames by 36 x- or y-coordinates)\n",
        "#...#\n",
        "sample = 0\n",
        "plt.imshow(X_train[sample])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UskFsQfRxAya"
      },
      "source": [
        "Then, run the following cell below to treat each frame as time on the x-axis, and each of the 36 numbers represented to x- or y-coordinate of the joint on the screen as individual series.  \n",
        "\n",
        "The code to do so looks like the following:\n",
        "\n",
        "```\n",
        "sample = 0\n",
        "plt.plot(X_train[sample])\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZWjTkiOWiWq"
      },
      "source": [
        "X_train[0].shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DrMOwZuswwAb"
      },
      "source": [
        "# TODO:\n",
        "# Plot each individual frame along the x (time) axis, and\n",
        "# treat each line as a series.\n",
        "#...#\n",
        "sample = 0\n",
        "plt.plot(X_train[sample])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQSbweXAxdm7"
      },
      "source": [
        "Both the visualizations above provides some visual clue as to how the different joints move over time, but they are still difficult to imagine and visualize.\n",
        "\n",
        "Update the following cell below to do a scatter plot of the X and Y coordianates of the various joints and animating them so that we can see their movements over time.\n",
        "\n",
        "To do so, you must:\n",
        "\n",
        "1. Set the data from your x_train to the scatter plot.\n",
        "\n",
        "   ```\n",
        "    graph_x = x_train[sample][frame][0::2]\n",
        "    graph_y = x_train[sample][frame][1::2]\n",
        "    line.set_data(graph_x, graph_y)\n",
        "    return line,\n",
        "   ```\n",
        "\n",
        "2. Set the X- and Y-axis limits to 0-800 and 600-0 respectively this way:\n",
        "\n",
        "    ```\n",
        "    ax.set_xlim(0, 800)\n",
        "    ax.set_ylim(600, 0)\n",
        "    ```\n",
        "\n",
        "3. Call the matplotlib's animation library to animate your points:\n",
        "\n",
        "    ```\n",
        "    anim = animation.FuncAnimation(fig, animate_pose, 32,  interval=50, blit=True)\n",
        "    rc('animation', html='jshtml')\n",
        "    anim\n",
        "```\n",
        "\n",
        "NOTE: These are the various types of actions captured in the dataset:\n",
        "JUMPING, JUMPING_JACKS, BOXING, WAVING_2HANDS, WAVING_1HAND\", \"CLAPPING_HANDS\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOY6GK6MYiiE"
      },
      "source": [
        "sample = 20000\n",
        "\n",
        "# This function returns a set of data for every frame that is\n",
        "# called from the animation.FuncAnimation below.\n",
        "#\n",
        "def animate_pose(frame):\n",
        "    # TODO:\n",
        "    # Retrieve the even number values as X-coordinates\n",
        "    # and the odd number values as Y-coordinates\n",
        "    #\n",
        "    # Once you have these 2 sets of values, you can\n",
        "    # pass them into the line.set_data to get matplotlib\n",
        "    # to draw a scatter plot \n",
        "    #\n",
        "    #...#\n",
        "    graph_x = X_train[sample][frame][0::2]\n",
        "    graph_y = X_train[sample][frame][1::2]\n",
        "    line.set_data(graph_x, graph_y)\n",
        "    return line,\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "plt.close()\n",
        "\n",
        "# TODO:\n",
        "# Set the x-limit and the y-limit of the animated scatter-plot chart\n",
        "# Use x-limit = (0, 800), y-limit = (600, 0) for the original raw coordinates\n",
        "# Use x-limit = (-4, 4), y-limit = (-3, 3) for the processed coordinates\n",
        "#...#\n",
        "\n",
        "# ax.set_xlim(0, 800)\n",
        "# ax.set_ylim(600, 0)\n",
        "ax.set_xlim(-4, 4)\n",
        "ax.set_ylim(3, -3)\n",
        "\n",
        "\n",
        "line, = ax.plot([], [], 'o', color='black');\n",
        "\n",
        "# TODO:\n",
        "# Trigger the matplotlib's animation function and pass in\n",
        "# the animate_pose function above. Additionally, write the necessary\n",
        "# codes to run the animation within colab.\n",
        "#\n",
        "# NOTE: The following codes may not work when running within Jupyter notebook\n",
        "#\n",
        "#...#\n",
        "anim = animation.FuncAnimation(fig, animate_pose, 32,  interval=50, blit=True)\n",
        "rc('animation', html='jshtml')\n",
        "anim"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m6y1JZMtexJx"
      },
      "source": [
        "## Section 6 - Define and Train Your Model\n",
        "\n",
        "Try to define your Keras sequential model using any Keras layers. You should have minimally:\n",
        "\n",
        "1. At least 1 RNN, or GRU, or LSTM Layer\n",
        "2. At least 1 Dense Layer (for the softmax classification)\n",
        "3. The input shape should be (32, 36)\n",
        "\n",
        "Try to experiment and find a suitable model. You can decide if you want to use Bidirectional models, and add any Dropout layers if it helps to improve your model performance. Share your model with the class together with the validation accuracy!\n",
        "\n",
        "A typical model can be designed this way:\n",
        "\n",
        "```\n",
        "    model.add(LSTM(128, input_shape=(32, 36)))\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    model.add(Dense(6, activation='softmax'))\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    model.summary()\n",
        "```\n",
        "\n",
        "This is part of model selection and evaluation in any machine learning project. \n",
        "\n",
        "You may find that a good validation accuracy for you model may hover near about 85-90%. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9B41N94QexJx"
      },
      "source": [
        "# Create our LSTM model here\n",
        "#\n",
        "def create_model():\n",
        "\n",
        "    # Use Keras to create a Sequential model here with any layers that \n",
        "    # you'd like.\n",
        "    #\n",
        "    model = Sequential()\n",
        "\n",
        "    # TODO:\n",
        "    # Apply your Keras knowledge and create your layers\n",
        "    #\n",
        "    #...#\n",
        "    model.add(LSTM(128, input_shape=(32, 36)))\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    model.add(Dense(6, activation='softmax'))\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    model.summary()\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "# Create our model\n",
        "#\n",
        "model = create_model()\n",
        "\n",
        "\n",
        "# Create the training folder\n",
        "#\n",
        "training_session_id = datetime.now().strftime(\"%Y-%m-%d %H-%M-%S\")\n",
        "training_session_folder = '/train_%s' % (training_session_id)\n",
        "os.makedirs(training_session_folder, exist_ok=True)\n",
        "\n",
        "# Configure the checkpoint and stop point.\n",
        "# This allows the training to save the best models and also stop the\n",
        "# training early if it detects that there are no improvements after\n",
        "# a long time.\n",
        "#\n",
        "callbacks_list = [\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        filepath=training_session_folder + '/model.{epoch:04d}-val_acc-{val_accuracy:4.2f}-loss-{val_loss:4.2f}.h5',\n",
        "        monitor='val_loss', save_best_only=True),\n",
        "    keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "]\n",
        "\n",
        "\n",
        "# Train our model\n",
        "#\n",
        "history = model.fit(x=X_train, y=y_train, batch_size=200, epochs=20, verbose=1, callbacks=callbacks_list, validation_data=(X_test, y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ala7NfYFdNZ0"
      },
      "source": [
        "## Section 7 - Scale / Translation Normalization\n",
        "\n",
        "So far, we have not talked about how we can normalize our skeletal keypoints so that the pose data is scale / translation invariant. This means that regardless of how far the person is from the camera, or when the person moves left or right or up or down, the coordinates of all joint positions should always be relative to a fixed frame of reference.\n",
        "\n",
        "To take care of translation (left / right / up / down) invariance, we are shift all points together so that neck point is always placed at (0, 0). \n",
        "\n",
        "To take care of scale invariance, we estimate the torso height (which is either the length of the neck point to either hip, or the width of the shoulders). We then divide all joint coordinates by the torso height.\n",
        "\n",
        "To do so, update the following the process_joints function to include code to normalize the skeleton key points as described above:\n",
        "\n",
        "1. ref = P[1] or the midpoint of P[2], P[5]\n",
        "2. reflength = length(ref to P[8]) or length(ref to P[11]) \n",
        "3. Compute \n",
        "   - P[i].x = (P[i].x - ref.x) / reflength\n",
        "   - P[i].y = (P[i].y - ref.y) / reflength\n",
        "\n",
        "```\n",
        "\n",
        "# Declare a function that can compute length between two points\n",
        "#   (x1,y1) - (x2,y2)\n",
        "#\n",
        "def compute_length(x1, y1, x2, y2):\n",
        "    return math.sqrt((x1-x2)*(x1-x2) + (y1-y2)*(y1-y2))\n",
        "\n",
        "# Process OpenPose's Joints\n",
        "# NOTE: The \"x\" parameter consists of an array of consecutive x and y values \n",
        "# within the same array.\n",
        "#\n",
        "# x = [p0.x, p0.y, p1.x, p1.y, p2.x, p2.y, ..., p17.x, p17.y]\n",
        "#     (a total of 36 values)\n",
        "# \n",
        "def process_joints(x):\n",
        "\n",
        "    r = [0] * 36\n",
        "\n",
        "    # Initialize some values for the reference length and the reference point.\n",
        "    #\n",
        "    refx = 0\n",
        "    refy = 0\n",
        "    reflength = 1\n",
        "\n",
        "    # Step 1: Let's find the reference point (neck)\n",
        "    #\n",
        "    if x[2] != 0 or x[3] != 0:         \n",
        "        refx = x[2]                # use the neck X, Y\n",
        "        refy = x[3]\n",
        "    elif (x[4] != 0 or x[5] != 0) and (x[10] != 0 or x[11] != 0):\n",
        "        refx = (x[4] + x[10]) / 2  # estimate the neck X, Y from the mid point\n",
        "        refy = (x[5] + x[11]) / 2  # of the left/right shoulder\n",
        "    \n",
        "    # Step 2: Let's first estimate the torso length.\n",
        "    #\n",
        "    if x[16] != 0 and x[17] != 0:             \n",
        "        reflength = compute_length(x[16], x[17], refx, refy)   # neck to right hip\n",
        "    elif x[22] != 0 and x[23] != 0:\n",
        "        reflength = compute_length(x[22], x[23], refx, refy)   # neck to left hip\n",
        "\n",
        "    # Step 3:\n",
        "    # Perform the translation and the scaling.\n",
        "    #\n",
        "    for i in range(0, 18):\n",
        "        r[i*2] = (x[i*2] - refx) / reflength\n",
        "        r[i*2 + 1] = (x[i*2 + 1] - refy) / reflength\n",
        "    \n",
        "    # Return the re-mapped and normalized result\n",
        "    #\n",
        "    return r\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjjvsyUVdMMS"
      },
      "source": [
        "# TODO:\n",
        "# Declare a function that can compute length between two points\n",
        "#   (x1,y1) - (x2,y2)\n",
        "#\n",
        "def compute_length(x1, y1, x2, y2):\n",
        "    return math.sqrt((x1-x2)*(x1-x2) + (y1-y2)*(y1-y2))\n",
        "\n",
        "# Process OpenPose's Joints\n",
        "# NOTE: The \"x\" parameter consists of an array of consecutive x and y values \n",
        "# within the same array.\n",
        "#\n",
        "# x = [p0.x, p0.y, p1.x, p1.y, p2.x, p2.y, ..., p17.x, p17.y]\n",
        "#     (a total of 36 values)\n",
        "# \n",
        "def process_joints(x):\n",
        "\n",
        "    r = [0] * 36\n",
        "\n",
        "    # TODO:\n",
        "    # Initialize some values for the reference length and the reference point.\n",
        "    #\n",
        "    refx = 0\n",
        "    refy = 0\n",
        "    reflength = 1\n",
        "\n",
        "    # TODO:\n",
        "    # Step 1: Let's find the reference point (neck)\n",
        "    #\n",
        "    if x[2] != 0 or x[3] != 0:         \n",
        "        refx = x[2]                # use the neck X, Y\n",
        "        refy = x[3]\n",
        "    elif (x[4] != 0 or x[5] != 0) and (x[10] != 0 or x[11] != 0):\n",
        "        refx = (x[4] + x[10]) / 2  # estimate the neck X, Y from the mid point\n",
        "        refy = (x[5] + x[11]) / 2  # of the left/right shoulder\n",
        "    \n",
        "    # TODO:\n",
        "    # Step 2: Let's first estimate the torso length.\n",
        "    #\n",
        "    if x[16] != 0 and x[17] != 0:             \n",
        "        reflength = compute_length(x[16], x[17], refx, refy)   # neck to right hip\n",
        "    elif x[22] != 0 and x[23] != 0:\n",
        "        reflength = compute_length(x[22], x[23], refx, refy)   # neck to left hip\n",
        "\n",
        "    # TODO:\n",
        "    # Step 3:\n",
        "    # Perform the translation and the scaling.\n",
        "    #\n",
        "    for i in range(0, 18):\n",
        "        r[i*2] = (x[i*2] - refx) / reflength\n",
        "        r[i*2 + 1] = (x[i*2 + 1] - refy) / reflength\n",
        "    \n",
        "    # Return the re-mapped and normalized result\n",
        "    #\n",
        "    return r\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GfwTTn0pahtB"
      },
      "source": [
        "## Section 8 - Re-Load the Data and Re-Train Your Model Again\n",
        "\n",
        "At this juncture, re-run the cells under the following sections again without changing the model or training parameters:\n",
        "\n",
        "- Section 4 - Processing the Data\n",
        "- Section 6 - Define and Train Your Model\n",
        "\n",
        "See how the model's training and validation accuracy has changed after normalizating the data.\n",
        "\n",
        "**Discuss:**\n",
        "\n",
        "1. Why did the normalization cause a change in the training / validation performance?\n",
        "2. What do you think you can do to improve performance instead of normalizating the data?\n",
        "3. Other than scaling / translating the points, what other kinds of normalization can you do?\n",
        "4. What are the downsides to normalizing the data?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dSEkWzoPZrK8"
      },
      "source": [
        "## Section 9 - Evaluate the Training History and Performance\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AaLsWwktYfM5"
      },
      "source": [
        "#------------------------------------------------------------------------------------------\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# This function is used to display the history the train/test accuracy/loss\n",
        "# of the Keras training.\n",
        "#\n",
        "#   history - Pass in the history returned from the model.fit(...) method.\n",
        "#\n",
        "def display_training_loss_and_accuracy(history):\n",
        "    \n",
        "    plt.figure(figsize=(20,4))\n",
        "    \n",
        "    # summarize history for accuracy\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['accuracy'])\n",
        "    plt.plot(history.history['val_accuracy'])\n",
        "    plt.title('model accuracy')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'test'], loc='upper left')\n",
        "    \n",
        "    # summarize history for loss\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title('model loss')\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'test'], loc='upper right')\n",
        "    plt.show()    \n",
        "\n",
        "display_training_loss_and_accuracy(history)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNGdcap1c-FE"
      },
      "source": [
        "labels = [\"JUMPING\", \"JUMPING_JACKS\", \"BOXING\", \"WAVING_2HANDS\", \"WAVING_1HAND\", \"CLAPPING_HANDS\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQxWAL8vYh6B"
      },
      "source": [
        "#------------------------------------------------------------------------------------------\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from functools import reduce\n",
        " \n",
        "def display_classification_confusion_matrix(keras_model, x_train, y_train, x_test, y_test, labels):\n",
        "    \n",
        "    '''\n",
        "    x_train = []\n",
        "    x_test = []\n",
        "    y_train = []\n",
        "    y_test = []\n",
        "    '''\n",
        "    pred_y_train = []\n",
        "    pred_y_test = []\n",
        "\n",
        "    print (x_train.shape)\n",
        "    pred_y_train = keras_model.predict(x_train)\n",
        "\n",
        "    x_train = np.array(x_train)\n",
        "    y_train = np.array(y_train)\n",
        "    pred_y_train = np.array(pred_y_train)\n",
        "\n",
        "    pred_y_test = keras_model.predict(x_test)\n",
        "\n",
        "    x_test = np.array(x_test)\n",
        "    y_test = np.array(y_test)\n",
        "    pred_y_test = np.array(pred_y_test)\n",
        "\n",
        "    #test_generator.on_epoch_end()\n",
        "\n",
        "    plt.figure(figsize=(20,6))  \n",
        "\n",
        "    labels = np.array(labels)\n",
        "\n",
        "    # Convert the target labels into the categorical index\n",
        "    #\n",
        "    y_train_index = y_train.argmax(axis=1)\n",
        "    pred_y_train_index = pred_y_train.argmax(axis=1)\n",
        "    y_test_index = y_test.argmax(axis=1)\n",
        "    pred_y_test_index = pred_y_test.argmax(axis=1)\n",
        "    \n",
        "    # Print the first Confusion Matrix for the training data\n",
        "    #\n",
        "    cm = confusion_matrix(y_train_index, pred_y_train_index)\n",
        "\n",
        "    cm_df = pd.DataFrame(cm, labels, labels)          \n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.title('Confusion Matrix (Train Data)')\n",
        "    sns.heatmap(cm_df, annot=True)\n",
        "    plt.ylabel('Actual')\n",
        "    plt.xlabel('Predicted')        \n",
        "    \n",
        "    # Print the second Confusion Matrix for the test data\n",
        "    #    \n",
        "    cm = confusion_matrix(y_test_index, pred_y_test_index)\n",
        "    \n",
        "    cm_df = pd.DataFrame(cm, labels, labels)          \n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.title('Confusion Matrix (Test Data)')\n",
        "    sns.heatmap(cm_df, annot=True)\n",
        "    plt.ylabel('Actual')\n",
        "    plt.xlabel('Predicted')        \n",
        "    \n",
        "    plt.show()\n",
        "\n",
        "    # Finally display the classification reports\n",
        "    #\n",
        "    print (\"Train Data:\")\n",
        "    print (\"--------------------------------------------------------\")\n",
        "    print(classification_report(y_train_index, pred_y_train_index, target_names=labels))\n",
        "    print (\"\")\n",
        "    print (\"Test Data:\")\n",
        "    print (\"--------------------------------------------------------\")\n",
        "    print(classification_report(y_test_index, pred_y_test_index, target_names=labels))\n",
        "    \n",
        "\n",
        "# Exclude the O tags from the confusion matrix.\n",
        "#\n",
        "display_classification_confusion_matrix(model, X_train, y_train, X_test, y_test, labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZELiB8MWdqt"
      },
      "source": [
        "## Section 9 - Save and Download Model\n",
        "\n",
        "Run the following cell to save your model. \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-uR1wAHpWjsm"
      },
      "source": [
        "model.save(\"model.savedmodel\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "206gJiXjibFz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1lEmBxaX1L4"
      },
      "source": [
        "Run the following the zip the \"model.savedmodel\" folder into a single zip file.\n",
        "\n",
        "Download that zip file from Colab once you are done! We will be using this for the next practical exercise."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_ofnOO6XR6K"
      },
      "source": [
        "!zip model.savedmodel.zip -r model.savedmodel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTissY5hib6b"
      },
      "source": [
        "model = keras.models.load_model('model.savedmodel')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQICBCSpiunz"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRTt3WWciwwD"
      },
      "source": [
        "labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nH8G--L3j-3l"
      },
      "source": [
        "sample_index = 2000\n",
        "sample = X_test[sample_index]\n",
        "label = y_test[sample_index]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFNSGnxIi0CB"
      },
      "source": [
        "sample = np.expand_dims(sample, axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_OUGrQT2jVz6"
      },
      "source": [
        "pred = model(sample)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBmuHkffjehb"
      },
      "source": [
        "print('actual = {}'.format(labels[np.argmax(label)]))\n",
        "print('predicted = {}'.format(labels[np.argmax(pred)]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "csvx4u4NjnHm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}