{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "multi-class-image-classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python3.8 (tf2env)",
      "language": "python",
      "name": "tf2env"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nyp-sit/it3103-tutors/blob/main/week3/multi_class_image_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0RZIgnFFEv5t"
      },
      "source": [
        "# Lab Exercise: Multi-class Image Classification\n",
        "\n",
        "Now that you have learnt how to train a model to do binary image classification of cats and dogs using Convolutional Neural Network. \n",
        "\n",
        "Modify the code to train a model to recognise whether a hand gesture is one of the gesture in the rock, paper and scissor game. \n",
        "\n",
        "The dataset of rock paper scissor can be downloaded from https://nypai.s3-ap-southeast-1.amazonaws.com/datasets/rps2.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "22qK2vQiEqgB"
      },
      "source": [
        "### Step 1: Import the necessary packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0Widz3qoiVr"
      },
      "source": [
        "import os \n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import optimizers\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKGTrOeiEzmP"
      },
      "source": [
        "### Step 2: Download Datasets\n",
        "\n",
        "Download the dataset and unzip the file to a folder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YH_eNtAbn78U"
      },
      "source": [
        "dataset_URL = 'https://nypai.s3-ap-southeast-1.amazonaws.com/datasets/rps2.zip'\n",
        "path_to_zip = tf.keras.utils.get_file('rps2.zip', origin=dataset_URL, extract=True, cache_dir='.')\n",
        "print(path_to_zip)\n",
        "PATH = os.path.join(os.path.dirname(path_to_zip), 'rps2')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qcaiLftXEONn"
      },
      "source": [
        "### Step 3: Set up your train and validation directory. \n",
        "\n",
        "Examine your dataset folder and set your train_dir and validation_dir to point to the correct directories."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9N0WuIbxwJGb"
      },
      "source": [
        "train_dir = os.path.join(PATH, 'train')\n",
        "validation_dir = os.path.join(PATH, 'validation')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jk2edwW2FJ1d"
      },
      "source": [
        "### Step 4: Set up the ImageDataGenerator \n",
        "\n",
        "Set up the ImageDataGenerator for both train and validation set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5-bXiSWoFtW"
      },
      "source": [
        "# All images will be rescaled by 1./255\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        # This is the target directory\n",
        "        train_dir,\n",
        "        # All images will be resized to 150x150\n",
        "        target_size=(150, 150),\n",
        "        batch_size=20,\n",
        "        # since our dataset has more than 3 classes, we will choose either categorical or sparse categorical\n",
        "        # this must match with the loss function we choose in our model\n",
        "        class_mode='sparse')\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "        validation_dir,\n",
        "        target_size=(150, 150),\n",
        "        batch_size=20,\n",
        "        class_mode='sparse')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WqZmYV4VxLQ8"
      },
      "source": [
        "for data_batch, labels_batch in train_generator:\n",
        "    print('data batch shape:', data_batch.shape)\n",
        "    print('labels batch shape:', labels_batch.shape)\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BpaO7BJVxkAO"
      },
      "source": [
        "You can see the labels is **NOT** one-hot-encoded.  Try changing the class_mode to 'categorical' and observe that the label will be one-hot-encoded."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IrSOVvwfFpcz"
      },
      "source": [
        "Print out the class indices so that you know what label is assigned to which class.  Hint: use ``class_indices`` of the generator."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPs--CSYvpmT"
      },
      "source": [
        "train_generator.class_indices"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S4kbK7XpGLYc"
      },
      "source": [
        "### Step 5: Create your model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ZCiZLK9vupW"
      },
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu',\n",
        "                        input_shape=(150, 150, 3)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(512, activation='relu'))\n",
        "model.add(layers.Dense(3, activation='softmax'))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2It5kjbGZA0"
      },
      "source": [
        "### Step 6: Compile and Train the Model\n",
        "\n",
        "Make sure you choose the correct loss function. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTPLmxO5IvaD"
      },
      "source": [
        "def create_tb_callback(): \n",
        "    \n",
        "    root_logdir = os.path.join(os.curdir, \"tb_logs\")\n",
        "\n",
        "    def get_run_logdir():    # use a new directory for each run\n",
        "\t    import time\n",
        "\t    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
        "\t    return os.path.join(root_logdir, run_id)\n",
        "\n",
        "    run_logdir = get_run_logdir()\n",
        "\n",
        "    tb_callback = tf.keras.callbacks.TensorBoard(run_logdir)\n",
        "\n",
        "    return tb_callback"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JaTbltHQxCzq"
      },
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer=optimizers.RMSprop(learning_rate=1e-4),\n",
        "              metrics=['acc'])\n",
        "\n",
        "tb_callback = create_tb_callback()\n",
        "\n",
        "earlystop_callback = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_acc', patience=10, verbose=0,\n",
        "    mode='auto', restore_best_weights=True\n",
        ")\n",
        "\n",
        "history = model.fit(\n",
        "      train_generator,\n",
        "      steps_per_epoch=126,\n",
        "      epochs=30,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps=18, callbacks=[earlystop_callback, tb_callback])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vOXpmCBGI8Ql"
      },
      "source": [
        "%load_ext tensorboard \n",
        "%tensorboard --logdir tb_logs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4i3Z8WIQJLi1"
      },
      "source": [
        "### Step 7: Save your Model\n",
        "\n",
        "Save your model for use in inference later on."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PprYt9Sz0oUM"
      },
      "source": [
        "model.save(\"rps_model\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TkWGYOK4HGBE"
      },
      "source": [
        "### Test your model\n",
        "\n",
        "The following code cells shows you how to set up Google Colab to take a picture using your webcam. Take a picture of your hand gesture (rock, paper or scissors) and infer using your saved model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWkCXDE70WiA"
      },
      "source": [
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "\n",
        "def take_photo(filename='photo.jpg', quality=0.8):\n",
        "  js = Javascript('''\n",
        "    async function takePhoto(quality) {\n",
        "      const div = document.createElement('div');\n",
        "      const capture = document.createElement('button');\n",
        "      capture.textContent = 'Capture';\n",
        "      div.appendChild(capture);\n",
        "\n",
        "      const video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "\n",
        "      document.body.appendChild(div);\n",
        "      div.appendChild(video);\n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      // Resize the output to fit the video element.\n",
        "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "      // Wait for Capture to be clicked.\n",
        "      await new Promise((resolve) => capture.onclick = resolve);\n",
        "\n",
        "      const canvas = document.createElement('canvas');\n",
        "      canvas.width = video.videoWidth;\n",
        "      canvas.height = video.videoHeight;\n",
        "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "      stream.getVideoTracks()[0].stop();\n",
        "      div.remove();\n",
        "      return canvas.toDataURL('image/jpeg', quality);\n",
        "    }\n",
        "    ''')\n",
        "  display(js)\n",
        "  data = eval_js('takePhoto({})'.format(quality))\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "  with open(filename, 'wb') as f:\n",
        "    f.write(binary)\n",
        "  return filename"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qp5MYbtv0WiD"
      },
      "source": [
        "from IPython.display import Image\n",
        "try:\n",
        "  filename = take_photo()\n",
        "  print('Saved to {}'.format(filename))\n",
        "  \n",
        "  # Show the image which was just taken.\n",
        "  display(Image(filename))\n",
        "except Exception as err:\n",
        "  # Errors will be thrown if the user does not have a webcam or if they do not\n",
        "  # grant the page permission to access it.\n",
        "  print(str(err))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jm3XARik0eT_"
      },
      "source": [
        "img = keras.preprocessing.image.load_img(\n",
        "    filename, target_size=(150, 150)\n",
        ")\n",
        "\n",
        "# we convert the image to numpy array\n",
        "img_array = keras.preprocessing.image.img_to_array(img)\n",
        "\n",
        "# Although we only have single image, however our model expected data in batches\n",
        "# so we will need to add in the batch axis too\n",
        "img_array = tf.expand_dims(img_array, 0) # Create a batch\n",
        "\n",
        "# we load the model saved earlier and do the inference \n",
        "model = tf.keras.models.load_model('rps_model')\n",
        "predicted_label = model.predict(img_array)\n",
        "# or predicted_label = model(img_array)\n",
        "\n",
        "print(predicted_label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHvhn8Dk1zVF"
      },
      "source": [
        "print(train_generator.class_indices)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}